---
tags  : [Screening]
category: [Screening]
---

## Current Title: Animacy, Empathy Locus, and Logophoricity: An Individual-Differences Analysis of Reflexive Pronoun Resolution in Mandarin Chinese

## My thoughts 
- things to talk about with Elsi:
  - Jun's thesis, meeting with Jun, and my ideas
  - Maybe consider submitting to camp?
  - the cogsci x gorilla grant if I want to recruit adult speakers for the classifier project (also Erjing's acquisition data)

## current research questions 
1. How syntactic factors (e.g., locality) and non-syntactic factors (e.g., animacy, logophoricity, empathy) impact reflexive resolution in Chinese?
   - Does the empathy locus and the discourse role (e.g., source vs. perceiver) of the perspective center impact LD binding of ziji?
   - Does the locality impact LD binding of ziji?
2. Do individual differences play a role in LD binding of ziji?

## Competition between Empathy, Logophor, and animacy hierarchies 

**Overall**: Syntactic constraint (binding) vs. Non-syntax constraints (empathy, logophoricity, and animacy)

<img width="762" height="180" alt="Screenshot 2025-08-28 at 10 39 09" src="https://github.com/user-attachments/assets/4c15528b-4751-4ee9-ba4f-3a6d0baf4ef4" />

**Empathic** = Empathy locus, a person whose perspective the speaker takes (perspective-taking, empathizes with the LD antecedent)

**Logophoric** = speech initiators or sources = reporting/perceiving

**differences**: Logophoricity is related to the notion of **perspective-reporting**, while empathy is related to the notion of **perspective-taking**

Based on previous research from theoretical work, which shows that ziji is both empathic and logophoric, and from experimental work, Liu (2020) found that ziji is logophoric, while Xue & Runner (submitted) found that ziji is not logophoric. 

**1. Empathy hierarchy (Hu, 2019)**
- Empathy verb > non-empathy verb (source and perciver verbs)

**Speech Act Empathy Hierarchy** (Kuno, 1987: 212)
- The speaker cannot empathize with someone else more than with himself (speaker只能对自己更empathize比起其他人)

  
**2. Logophority hierarchy**
- Source > Self > Pivot (Huang & Liu, 2001)
- Speech > thought > knowledge > direct perception (Culy, 1994; 1062)
- overall: source > preceiver

**3. Animacy hierarchy in grammar and typology (Ji & Liang, 2018)**
<img width="718" height="98" alt="Screenshot 2025-09-01 at 09 29 02" src="https://github.com/user-attachments/assets/6fc905e3-1778-495e-b21a-04d265e9bd60" />

**Animacy hierarchy within inanimate nouns (Ji & Liang, 2018)**
- collective nouns > spatial and temporal nouns > concrete nouns > psychological nouns > other abstract nouns

**4. Empathy x Logophority x Animacy Hierarchy (Hu, 2019)**
- Empathy hierarchy (empathy verb, source verb, preceiver verb) > Animacy hierarchy (animate + human, animate nouns, inanimate nouns)
- Animate + human noun > animate noun > inanimate noun

## Hypothesis
  - Then it shows that if the empathy x logophority x animacy hierarchy (Hu, 2019) is true, then a faster reaction time for the empathy verb compared to the source and preceiver verb
  - If the animacy hierarchy is true, then animate + human nouns have faster reaction times than animate -human nouns
  - then we expect: 
    - fastest reaction time to the empathy and animate +human noun condition
    - lowest reaction time to the perceiver and inanimate noun condition

**Another Empathy Hierarchy and its interaction with Animacy (Langacker, 1991:306--307)**
- **Empathy hierarchy**: speaker (source?) > hearer (preciever?) > human (names) > animal > physical object > abstract entity (collective nouns)
  - tends to empathize with the speaker, then the hearer, then the human, then the collective nouns

## Central question from Jun: 
- whether syntactic information is prioritized over non-syntactic information (e.g., gender, number, animacy) in early-stage processing
  1. the standard cue-based retrieval model (e.g., Lewis & Vasishth, 2005; Van Dyke & McElree, 2006; Chen et al., 2012; Jäger et al., 2015; Patil et al., 2016)
  2. the structure-based retrieval model (e.g., Sturt, 2003; Xiang et al., 2009; Van Dyke & McElree, 2011; Dillon et al., 2013; Cunnings & Sturt, 2014; Parker & Phillips, 2017)


## My thoughts 
- 3 x 2 design?
- empathy verb (fear, haipa), source verb (tell, gaosu), preceiver verb (hear, tingshuo)
- animate noun, collective noun (John, university) 
  -  ziji may be more likely to bound with singular nouns like john, and if we do not add another level of plural nouns, this might be a part of nature for the collective noun, since they may be plural by nature, and this may be a confounding variable.
  -  questions:  collective plural noun
 

## Before experiment (norming?)
- ask participants to rate the animacy AND plurality of the nouns first from 1-10 to create a gradient effect, because some collective nouns may be more animate than others, then select the top-rated collective nouns from the survey

## experiment 
- reaction time
  - Self-paced reading
- individual difference in 2 domains
  1. Cognitive processing style
    - ASQ
    - Big five personabilities?
  2. working memory capacity
  - working memory? Even though they did not find a significance, but based on their research seems to be relevant, also it has an effect on language processing.

- **working memory capacity (WMC)**: the ability to control attention and deal with irrelevant information, and not simply the amount of information that can reside in working memory. = individual differences are not due to some limited amount of activation available to the working memory system, but to an individual's ability to ignore irrelevant information (on the basis of a specific relevant goal) through the control of attention
- Individuals with lower WMC are less able to utilize executive control to ignore irrelevant or interfering information and maintain focus on a specific goal. whereas the opposite is true for high-WMC individuals.
- Working memory has an effect on speech processing.
  - Increasing WM load has been shown to slow down spoken word recognition, high working memory individuals show less perceptual compensation for coarticulation and are less biased toward hearing legal sound sequences than low working memory individuals.

