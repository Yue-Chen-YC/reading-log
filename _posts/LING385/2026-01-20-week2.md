---
tags  : [TA, Ling 385]
category: [TA, Ling 385]
---
## Week 2
- the child needs to average across these things
- this won't work with more complex things like language, biological molecules, scenes, etc
- stochastic gradient descent = sgd
  - the essence of how proteins behave
    - steps
      - pick any random number x as the estimate of average and we will improve it by sbservation, we are at time 0, let's say the random number we pick is 130: x[0] = 130
      - randomly pick a number d from the data, so we can see how far the data is from the estimate, as the average should be close to the data, d[0] = 98
      - x [0] = 130 and d[0] = 98, the mistake we've made is loss = 130 -98= 32
      - we want our new estimate to be with the old estimate
        -  x[1] = x[0] - 10% of 32
        -  x[1] = 130 - 3.2 = 126.8

      fundamental learning tradeoff
      - learninf rate higher, spead higher and accuracy higer
      - learning rate lower, spead lower, and accuracy lower
      - gemma = learning rate, we are making the agorithm faster about what we need to learn
      - epchoes is the times of learning
      - optimization = people are trying to figure out how we are going to change the learning rate, so we can learn faster and more accuratly
      - same dynmaic of x, change in x
     
  science is about connecting ideas?
  - if push masclies is it faster or slower
  - what's the relationship between the stifness and SGD = high stifness related to a high learning rate
 
search tree = search through the sentence 
- imagine we can observe many many differen sentences produced by people
- maybe we use a more genral version of sgd to learn the essence/average so similar sequences can be produced

dynamic programming 
- shortest path problem
  -  language produciton
  -  simple version of the language tree, a language speaker needs to produce 10,000 words
  -  the heart of ai is seeing similarities, how do we go through the network to pick out the path
    -  greedy algorithm = reinforcement learning
      - agent
       = enviorment
      - policy = decision
       - cost/reward
    - exhaustive alforithm = every single path by adding up the numbers, and write down the sum, go through every possible path and pick the least
      - speed accuracy trade off, very wastfull

  - dynamic programming
    - bellman: imagine we know the costs of the paths from B to J and C to J
    - we will call them VBJ and VCJ, then what's the best cost of a - j
    - VAJ = min {12 + VBJ, 7 + VCJ}
    - we don't know VCJ and VBJ
    - to slove this we need to do more imagining
    - this dynamic programming makes greedy work
   
search tree
- search trhough many words
- trees as branches
- monte carlo tree search
  - chance based systems
    - give one prompt, they are chance based systems
    - chance-related thing
      - the point of this, speaking human like sentences is through word path of these trees
      - ai is just like us to find pretty good path
      - highly expected sentences
      - going through path trhough space that is novel
      - most freqeunt path is not how we communicate
- the cost of english grammar
  - if the cost is fixed, some aspects of cost is updated in the real language
  - there's a word having to do with judged and lawyers
  - cost-realted production is dynamic

a basic sense of reinforcement learning, modern AI
- reinforcement learning
  - language production is quiet similar to the shortest path
  - stages = word number, states = words
  - in shortest path, an agent tries to select a good policy
  - agent tries to select a good policy
  - in language is what words should we produce
    - the costs are like grammatical knowledge
      - D --> H, the --> dog
      - D --> I, the --> eat is a bigger cost
    - in shortest path, you being speakers' english, you already started to learn language,  you learn the cost of English
    - how ai is going to learn all the costs and all the transitions to language
    - doing ai and teaching ai system to talk
      - figures out the rewards by itself
        - the should be followed by lawyer if we are talking about courts
        - shortest path from language production network
        - the grammatical structure, the creativity in language = cost strcuture in the shortest path
        - 2 modes in mordern ai
          - learning = first learn to speak
            - reward - cost strcuture
            - what is the true average from a lot of exmaples 
          - inference
            - infering a sentence = making a selection
            - when I ask a question to the ai system is based on what is already knows about what the responds would be
            - it can adopt its knowledge to u
            - small distinction, the learning or training such as pre-training
            - it fine-tunes = fine-tuning just changing the knwoedlge just a little bit

        - ai was able to come up with very good local policies to predict the next word from the previous words
          - the --> next word = cat, dog, lawyer
          - knowing the next word is is already enough to solve the language translation system
          - what should the next word be?
          - the languages have a lot of data to learn
          - the more these systems are trained, before this, there's a game to play with translation systems
          - what does these systems are able to do
          - knowing the rewards and how to act under the cost for the next word
          - nature language translation is not easy, it took 65 years to solve this problem
          - you can get translations from many many languages
          - how these systems are able to solve this next word problem
          - concpet from psychology
            - cloze test = the human ability to complete
            - human ability to see wholes, so even if we are given parts of an object or an occluded object, we know easily how to close the missing parts

- systems learned about applying dynamic programing and SGD to solve these problems
  - here's the approximation
  - we atart the system with random costs
  - we have all the text on the internet, pick 3 or any number of words from any sentence
