---
tags  : [TA, Ling 385]
category: [TA, Ling 385]
---
## Week 2
- the child needs to average across these things
- this won't work with more complex things like language, biological molecules, scenes, etc
- stochastic gradient descent = sgd
  - the essence of how proteins behave
    - steps
      - pick any random number x as the estimate of average and we will improve it by sbservation, we are at time 0, let's say the random number we pick is 130: x[0] = 130
      - randomly pick a number d from the data, so we can see how far the data is from the estimate, as the average should be close to the data, d[0] = 98
      - x [0] = 130 and d[0] = 98, the mistake we've made is loss = 130 -98= 32
      - we want our new estimate to be with the old estimate
        -  x[1] = x[0] - 10% of 32
        -  x[1] = 130 - 3.2 = 126.8

      fundamental learning tradeoff
      - learninf rate higher, spead higher and accuracy higer
      - learning rate lower, spead lower, and accuracy lower
      - gemma = learning rate, we are making the agorithm faster about what we need to learn
      - epchoes is the times of learning
      - optimization = people are trying to figure out how we are going to change the learning rate, so we can learn faster and more accuratly
      - same dynmaic of x, change in x
     
  science is about connecting ideas?
  - if push masclies is it faster or slower
  - what's the relationship between the stifness and SGD = high stifness related to a high learning rate
 
search tree = search through the sentence 
- imagine we can observe many many differen sentences produced by people
- maybe we use a more genral version of sgd to learn the essence/average so similar sequences can be produced

dynamic programming 
- shortest path problem
  -  language produciton
  -  simple version of the language tree, a language speaker needs to produce 10,000 words
  -  the heart of ai is seeing similarities, how do we go through the network to pick out the path
    -  greedy algorithm = reinforcement learning
      - agent
       = enviorment
      - policy = decision
       - cost/reward
    - exhaustive alforithm = every single path by adding up the numbers, and write down the sum, go through every possible path and pick the least
      - speed accuracy trade off, very wastfull

  - dynamic programming
    - bellman: imagine we know the costs of the paths from B to J and C to J
    - we will call them VBJ and VCJ, then what's the best cost of a - j
    - VAJ = min {12 + VBJ, 7 + VCJ}
    - we don't know VCJ and VBJ
    - to slove this we need to do more imagining
    - this dynamic programming makes greedy work
